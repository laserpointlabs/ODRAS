name: ODRAS Comprehensive CI

on:
  push:
    branches: [main, develop]  # Only run comprehensive tests on main/develop
  pull_request:
    branches: [main, develop]  # Run comprehensive tests on PRs
  workflow_dispatch:  # Allow manual trigger

jobs:
  comprehensive_odras_test:
    name: Comprehensive ODRAS System Test
    runs-on: ubuntu-latest
    timeout-minutes: 45
    # Only run comprehensive tests on main branch or PRs
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch'

    env:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: odras
      NEO4J_AUTH: neo4j/testpassword
      FUSEKI_ADMIN_PASSWORD: admin
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    # No GitHub Actions services - use ./odras.sh up instead for exact local setup

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Set up Java 21
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: "21"

      - name: Set up Docker Buildx (for caching)
        uses: docker/setup-buildx-action@v3

      - name: Free up disk space for CI
        run: |
          echo "üßπ Freeing up disk space for CI..."
          # Remove unnecessary packages and cached data
          sudo apt-get autoremove -y
          sudo apt-get autoclean
          # Clean Docker system (previous runs may accumulate)
          docker system prune -af --volumes || echo "Docker prune failed"
          # Remove old container logs
          sudo truncate -s 0 /var/lib/docker/containers/*/*-json.log 2>/dev/null || echo "No container logs to clear"
          # Remove unnecessary system packages to free space
          sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost 2>/dev/null || echo "Additional cleanup completed"
          
          echo "üìä Disk usage after cleanup:"
          df -h

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            postgresql-client \
            redis-tools \
            wget \
            curl \
            net-tools \
            docker-compose

          # Install Neo4j cypher-shell (modern GPG approach)
          echo "Installing Neo4j cypher-shell with Java 21..."
          wget -O /tmp/neo4j.asc https://debian.neo4j.com/neotechnology.gpg.key
          sudo gpg --dearmor -o /usr/share/keyrings/neo4j.gpg /tmp/neo4j.asc
          echo 'deb [signed-by=/usr/share/keyrings/neo4j.gpg] https://debian.neo4j.com stable latest' | sudo tee /etc/apt/sources.list.d/neo4j.list
          sudo apt-get update
          sudo apt-get install -y cypher-shell

          # Verify installation
          echo "Java version:"
          java -version
          echo "cypher-shell version:"
          cypher-shell --version || echo "cypher-shell installation failed"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio psycopg2-binary

      - name: Setup Ollama for CI
        uses: ai-action/ollama-action@v1
        with:
          model: 'llama3.2:1b'  # Lightweight model for CI
          prompt: 'System ready'  # Simple test to verify LLM works

      - name: Start ODRAS stack (CI-compatible)
        run: |
          echo "üöÄ Starting ODRAS stack (CI-compatible)..."
          # Clean up disk space before starting
          docker system prune -f --volumes
          
          # Start core services (Ollama handled by GitHub Action above)
          docker-compose up -d postgres redis neo4j fuseki qdrant camunda7 minio

          echo "Waiting for services to be ready..."
          sleep 20

          # Verify critical services (same as odras.sh)
          echo "Checking PostgreSQL..."
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres > /dev/null 2>&1; then
              echo "‚úÖ PostgreSQL ready"
              break
            fi
            sleep 2
          done

          echo "Checking Redis..."
          for i in {1..30}; do
            if redis-cli -h localhost -p 6379 ping > /dev/null 2>&1; then
              echo "‚úÖ Redis ready"
              break
            fi
            sleep 2
          done

          # Verify Ollama is available
          echo "Checking Ollama availability..."
          if ollama --version > /dev/null 2>&1; then
            echo "‚úÖ Ollama ready (GitHub Action)"
          else
            echo "‚ö†Ô∏è Ollama not available (some tests may be skipped)"
          fi
          
          echo "‚úÖ ODRAS stack ready"

      - name: Initialize database (EXACTLY like local)
        run: |
          echo "üóÑÔ∏è Running ./odras.sh init-db (SAME AS LOCAL)..."
          ./odras.sh init-db
          
          echo "üîç Testing database connection health..."
          python scripts/test_db_connection_health.py

      - name: Start ODRAS application (EXACTLY like local)
        run: |
          echo "üöÄ Starting ODRAS application using ./odras.sh start (SAME AS LOCAL)..."
          ./odras.sh start

          echo "Waiting for application startup..."
          sleep 30

          # Verify COMPLETE system
          echo "üîç Verifying COMPLETE ODRAS system..."

          # Check if uvicorn process is running
          echo "Checking if uvicorn process is running..."
          if ! pgrep -f "uvicorn.*main" > /dev/null && ! pgrep -f "python.*main" > /dev/null; then
            echo "‚ùå ERROR: Application process not found!"
            echo "Checking logs..."
            tail -50 /tmp/odras_app.log 2>/dev/null || echo "No logs found"
            exit 1
          fi
          echo "‚úÖ Application process is running"

          # API Health - wait longer and check more carefully
          echo "Waiting for API to be ready..."
          api_ready=false
          for i in {1..60}; do
            # Try health endpoint (curl will handle connection errors)
            health_response=$(curl -s -w "\n%{http_code}" --connect-timeout 5 --max-time 10 http://localhost:8000/api/health 2>/dev/null || echo -e "\n000")
            http_code=$(echo "$health_response" | tail -1)
            
            if [ "$http_code" = "200" ]; then
              health_data=$(echo "$health_response" | head -n -1)
              echo "‚úÖ ODRAS API responding (HTTP $http_code)"
              echo "üìä Health status: $health_data"
              api_ready=true
              break
            elif [ "$http_code" = "000" ]; then
              echo "API connection failed... ($i/60)"
            else
              echo "API returned HTTP $http_code... ($i/60)"
              # Log response for debugging
              if [ "$http_code" != "000" ]; then
                echo "$health_response" | head -n -1 | head -5
              fi
            fi
            sleep 2
          done

          if [ "$api_ready" = "false" ]; then
            echo "‚ùå ERROR: API health check failed after 120 seconds"
            echo "Application logs (last 100 lines):"
            tail -100 /tmp/odras_app.log 2>/dev/null || echo "No logs found"
            echo ""
            echo "Checking process status:"
            ps aux | grep -E "uvicorn|python.*main" | grep -v grep || echo "No process found"
            echo ""
            echo "Checking port 8000:"
            (netstat -tuln 2>/dev/null | grep 8000 || ss -tuln 2>/dev/null | grep 8000 || curl -s --connect-timeout 2 http://localhost:8000/api/health >/dev/null 2>&1 && echo "Port 8000 is accessible via curl" || echo "Port 8000 not accessible")
            exit 1
          fi

          # Service status
          service_status=$(curl -s http://localhost:8000/api/service-status || echo "Service status not available")
          echo "üìä Service status: $service_status"

          echo "üéØ COMPLETE ODRAS APPLICATION READY"
          
          # Test connection pool health after app startup
          echo "üîç Testing connection pool health after application startup..."
          python scripts/test_db_connection_health.py || {
            echo "‚ùå Connection pool health check failed!"
            echo "üìä Connection pool status:"
            curl -s http://localhost:8000/api/system/status 2>/dev/null || echo "Could not get system status"
            exit 1
          }

      - name: Run COMPLETE ODRAS system tests (IDENTICAL to local)
        run: |
          echo "üéØ Running COMPLETE ODRAS system tests (EXACT SAME AS LOCAL)"
          echo "============================================================"

          echo "üèÉ‚Äç‚ôÇÔ∏è Step 1: Fast DAS Health Check..."
          python scripts/fast_das_validator.py

          echo "üß™ Step 2: Enhanced Ontology Attributes Test..."
          python -m pytest tests/test_working_ontology_attributes.py -v --tb=short

          echo "üß™ Step 3: Baseline DAS Integration Test..."
          python tests/test_das_integration_comprehensive.py

          echo "üß™ Step 4: RAG System Stability Test..."
          python tests/test_rag_system_stability.py

          echo "üß™ Step 4.5: RAG Modularization Test..."
          python -m pytest tests/test_rag_modular.py -v --tb=short -m "not integration"

          echo "üß™ Step 4.6: RAG LLM Configuration Test..."
          python -m pytest tests/test_rag_llm_config.py -v --tb=short -m "not integration"

          echo "üß™ Step 4.7: RAG Hybrid Search and Reranker Test..."
          python -m pytest tests/test_rag_hybrid_search.py -v --tb=short -m "not integration"

          echo "üß™ Step 4.8: RAG Hybrid Search Evaluation Test..."
          python -m pytest tests/test_rag_hybrid_search_evaluation.py -v --tb=short -m "not integration"

          echo "üß™ Step 4.9: RAG Real-World Performance Evaluation..."
          python -m pytest tests/test_rag_real_world_evaluation.py -v --tb=short -s || echo "‚ö†Ô∏è Real-world evaluation requires running services"

          echo "üß™ Step 4.10: RAG CI Verification Test..."
          python -m pytest tests/test_rag_ci_verification.py -v --tb=short -m integration

          echo "üß™ Step 4.11: DAS Training Data Initialization Test..."
          echo "Checking if test file exists..."
          ls -la tests/test_training_data_initialization.py || echo "Test file not found!"
          echo "Running pytest with explicit output..."
          python -m pytest tests/test_training_data_initialization.py -v --tb=short -m integration -s 2>&1 || {
            echo "‚ùå Training data tests failed!"
            echo "Pytest exit code: $?"
            echo "Checking API status..."
            curl -s http://localhost:8000/api/health || echo "API not responding"
            echo "Checking training collections endpoint..."
            TOKEN=$(python3 -c "import httpx; r = httpx.post('http://localhost:8000/api/auth/login', json={'username': 'das_service', 'password': 'das_service_2024!'}, timeout=5); print(r.json()['token'] if r.status_code == 200 else 'FAILED')")
            curl -s -H "Authorization: Bearer $TOKEN" http://localhost:8000/api/das-training/collections || echo "Collections endpoint failed"
            exit 1
          }

          echo "üß™ Step 5: Ontology Inheritance System Test..."
          python -m pytest tests/test_inheritance_system.py -v --tb=short

          echo "üß™ Step 6: CQ/MT Workbench Test..."
          python scripts/cqmt_ui_test.py

          echo "üß™ Step 7: CQMT Dependency Tracking Test..."
          python -m pytest tests/test_cqmt_dependency_tracking.py -v --tb=short

          echo "üß™ Step 8: CQMT Change Detection Test..."
          python -m pytest tests/test_ontology_change_detection.py -v --tb=short

          echo "üß™ Step 9: Individual Tables CRUD Test..."
          python -m pytest tests/test_individuals_crud.py -v --tb=short

          echo "üß™ Step 10: Class Migration Test (XFAIL - Known Issues)..."
          python -m pytest tests/test_class_migration.py -v --tb=short || true

          echo "üß™ Step 11: Property Migration Test (XFAIL - Known Issues)..."
          python -m pytest tests/test_property_migration.py -v --tb=short || true

          echo "üß™ Step 12: CQMT Workbench Complete Test..."
          python -m pytest tests/test_cqmt_workbench_complete.py -v --tb=short

          echo "‚úÖ COMPLETE ODRAS system validation finished"
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Run tests with coverage
        run: |
          echo "üìä Running tests with coverage reporting..."
          pytest tests/ \
            --cov=backend \
            --cov-report=html \
            --cov-report=term \
            --cov-report=xml \
            --cov-fail-under=80 || echo "‚ö†Ô∏è Coverage below 80% or tests failed"
          echo ""
          echo "üß™ Running RAG Modularization Integration Tests..."
          python -m pytest tests/test_rag_modular.py -v --tb=short -m integration || echo "‚ö†Ô∏è RAG integration tests failed (may require running services)"
          echo ""
          echo "üß™ Running Phase 6: DAS Personas, Teams, MCP, and Learning Unit Tests..."
          python -m pytest tests/unit/test_persona_interface.py tests/unit/test_das_personas.py tests/unit/test_team_orchestrator_interface.py tests/unit/test_das_team_orchestrator.py tests/unit/test_mcp_client_interface.py tests/unit/test_das_mcp_client.py tests/unit/test_learning_interface.py tests/unit/test_das_learning.py -v --tb=short || echo "‚ö†Ô∏è Phase 6 unit tests failed"
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-${{ github.sha }}
          path: |
            htmlcov/
            coverage.xml
          retention-days: 30

      - name: COMPLETE system diagnostic report
        if: always()
        run: |
          echo "üìä COMPLETE ODRAS SYSTEM DIAGNOSTIC REPORT"
          echo "============================================================"

          echo "DATABASE TABLES:"
          PGPASSWORD=password psql -h localhost -U postgres -d odras -c "
          SELECT table_name FROM information_schema.tables
          WHERE table_schema = 'public'
          ORDER BY table_name;" || echo "PostgreSQL unavailable"

          echo "TEST USERS:"
          PGPASSWORD=password psql -h localhost -U postgres -d odras -c "
          SELECT username, is_admin, is_active FROM users ORDER BY username;" || echo "Users check failed"

          echo "QDRANT COLLECTIONS:"
          curl -s http://localhost:6333/collections | python -c "
          import json, sys
          try:
              data = json.load(sys.stdin)
              collections = data.get('result', {}).get('collections', [])
              print(f'Total collections: {len(collections)}')
              for c in collections:
                  print(f'  ‚úÖ {c}')
          except Exception as e:
              print(f'Qdrant check failed: {e}')
          " || echo "Qdrant unavailable"

          echo "NEO4J STATUS:"
          cypher-shell -a neo4j://localhost:7687 -u neo4j -p testpassword "
          CALL db.labels() YIELD label RETURN label LIMIT 10;
          " || echo "Neo4j unavailable"

          echo "REDIS STATUS:"
          redis-cli -h localhost -p 6379 info server | head -5 || echo "Redis unavailable"

          echo "FUSEKI STATUS:"
          curl -s http://localhost:3030/$/ping || echo "Fuseki unavailable"

          echo "CAMUNDA STATUS:"
          curl -s http://localhost:8080/engine-rest/version || echo "Camunda unavailable"

          echo "DEPLOYED PROCESS DEFINITIONS:"
          curl -s http://localhost:8080/engine-rest/process-definition | python -c "
          import json, sys
          try:
              data = json.load(sys.stdin)
              print(f'Process definitions: {len(data)}')
              for proc in data[:5]:
                  print(f'  ‚úÖ {proc.get(\"key\", \"unknown\")} - {proc.get(\"name\", \"no name\")}')
          except:
              print('No process definitions or Camunda unavailable')
          " || echo "Process definition check failed"

          echo "API LOGS (last 50 lines):"
          tail -50 /tmp/odras_api.log || echo "No API logs"

          echo "WORKER LOGS (last 20 lines):"
          tail -20 /tmp/odras_worker.log || echo "No worker logs"

          echo "============================================================"
          echo "üéâ ALL TESTS COMPLETED IN MAIN SECTION"
          echo "üìä System diagnostic and logs captured"
          echo "============================================================"

      - name: Upload DAS Test Reports
        uses: actions/upload-artifact@v4
        if: always() # Upload artifacts even if tests fail
        with:
          name: das-test-reports-${{ github.sha }}
          path: |
            /tmp/das_integration_test_*.log
            /tmp/odras_app.log
            /tmp/odras_complex_worker.log
            /tmp/odras_simple_worker.log
            /tmp/rag_test_*.log
          retention-days: 30

      - name: Upload DAS Performance Data
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: das-performance-data-${{ github.sha }}
          path: |
            /tmp/das_simple_metrics_*.json
            /tmp/*test_results*.json
            /tmp/*confidence*.json
            /tmp/*performance*.json
          retention-days: 90 # Keep performance data longer for trend analysis

  # REMOVED: das-integration-test job to eliminate port conflicts
  # DAS test now runs within main job using shared infrastructure
