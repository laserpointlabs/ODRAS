#!/usr/bin/env python3
"""
Debug the knowledge transformation pipeline to identify where it's failing
"""
import asyncio
import sys
import os
sys.path.append('/home/jdehart/working/ODRAS/backend')

from services.knowledge_transformation import get_knowledge_transformation_service
from services.config import Settings

async def debug_transformation():
    print("ğŸ”§ Debug Knowledge Transformation Pipeline")
    print("=" * 60)
    
    try:
        # Initialize the service
        print("ğŸ“Š Step 1: Initialize transformation service...")
        service = get_knowledge_transformation_service(Settings())
        print("âœ… Service initialized successfully")
        
        # Test with a known file ID from our earlier test
        print("\nğŸ“Š Step 2: Test file extraction...")
        # Let's get a file ID from the database first
        import psycopg2
        
        conn = psycopg2.connect(
            host="localhost", database="odras", user="postgres", 
            password="password", port=5432, connect_timeout=5
        )
        cur = conn.cursor()
        cur.execute("SELECT id, filename FROM files ORDER BY created_at DESC LIMIT 1")
        result = cur.fetchone()
        
        if not result:
            print("âŒ No files found in database")
            return
        
        file_id, filename = result
        print(f"âœ… Using file: {filename} ({file_id})")
        cur.close()
        conn.close()
        
        # Test each step of the pipeline
        print(f"\nğŸ“Š Step 3: Test text extraction...")
        try:
            extracted_text, extraction_metadata = await service.extract_text_content(file_id)
            print(f"âœ… Text extracted: {len(extracted_text)} characters")
            print(f"ğŸ“„ Preview: {extracted_text[:100]}...")
        except Exception as e:
            print(f"âŒ Text extraction failed: {e}")
            return
        
        print(f"\nğŸ“Š Step 4: Test chunking...")
        try:
            processing_config = {
                'chunking_strategy': 'hybrid',
                'chunk_size': 512,
                'chunk_overlap': 50,
                'document_type': 'unknown'
            }
            
            chunks = service.chunking_service.chunk_document(
                extracted_text,
                document_metadata=extraction_metadata,
                chunking_config=processing_config
            )
            print(f"âœ… Chunking successful: {len(chunks)} chunks created")
            
            if chunks:
                print(f"ğŸ“‹ Sample chunk:")
                chunk = chunks[0]
                print(f"  â€¢ Sequence: {chunk.metadata.sequence_number}")
                print(f"  â€¢ Type: {chunk.metadata.chunk_type}")
                print(f"  â€¢ Content length: {len(chunk.content)}")
                print(f"  â€¢ Content preview: {chunk.content[:100]}...")
                
        except Exception as e:
            print(f"âŒ Chunking failed: {e}")
            import traceback
            traceback.print_exc()
            return
        
        print(f"\nğŸ“Š Step 5: Test database connection...")
        try:
            # Test if database services work
            conn = service.db_service._conn()
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM knowledge_assets")
            count = cur.fetchone()[0]
            print(f"âœ… Database connection OK: {count} existing assets")
            cur.close()
            service.db_service._return(conn)
        except Exception as e:
            print(f"âŒ Database test failed: {e}")
            return
        
        print(f"\nğŸ“Š Step 6: Test Qdrant connection...")
        try:
            collections = service.qdrant_service.list_collections()
            print(f"âœ… Qdrant connection OK: {len(collections)} collections")
        except Exception as e:
            print(f"âŒ Qdrant test failed: {e}")
            return
        
        print(f"\nğŸ‰ All individual components working!")
        print(f"ğŸ” Now testing full transformation pipeline...")
        
        # Test full pipeline
        try:
            # Get a project ID 
            conn = psycopg2.connect(
                host="localhost", database="odras", user="postgres", 
                password="password", port=5432, connect_timeout=5
            )
            cur = conn.cursor()
            cur.execute("SELECT project_id FROM projects LIMIT 1")
            project_id = cur.fetchone()[0]
            cur.close()
            conn.close()
            
            print(f"ğŸ“ Using project: {project_id}")
            
            asset_id = await service.transform_file_to_knowledge(
                file_id=file_id,
                project_id=project_id,
                processing_options=processing_config
            )
            print(f"ğŸ‰ FULL TRANSFORMATION SUCCESS!")
            print(f"âœ… Knowledge asset created: {asset_id}")
            
        except Exception as e:
            print(f"âŒ Full transformation failed: {e}")
            import traceback
            traceback.print_exc()
            return
            
    except Exception as e:
        print(f"âŒ Debug failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(debug_transformation())
