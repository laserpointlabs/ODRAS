Lets build a specification for a new tool that can perform the following:<br>
<br>
- Manage users and projects<br>
- Extract requirements using a defined set of words like 'shall' from a set of uploaded files on a project basis<br>
- Extract requirements using other technicques (TBD)<br>
- Maintain meta-data for the upladed documents<br>
- Documents should be chunked, overlapped, and embedded in a vector store with associated meta-data<br>
- Extracted requirements should be embedded in a similar manor with meta-data<br>
- View, Edit, Save, Export, Version, and Extend the base ontology (see dadms ontology workbench local folder for and example)<br>
- The base ontology:<br>
    - Requirement --> has_constratint --> Constraint<br>
    - Requirement --> deploys --> Component<br>
    - Component --> present --> Interface<br>
    - Component --> performs --> Process<br>
    - Process --> realizes --> Function<br>
    - Function --> activates_on --> Condition<br>
    - Function --> specifically_depends_upon --> Component<br>
- Use react flow to help the user interact with devloped and extracted ontologies<br>
   - Present the ontology in a tree-view<br>
   - Allow the user to perform CRUD operations on Entities (Classes, Object Properties, Data Properties)<br>
   - Manage DataTypes<br>
   - Manage Annotation Properties<br>
   - Manage URI data<br>
- Store the ontologies in a RDF server (fuseki) and a graph database (neo4j)<br>
- Build an LLM Team and Manage Team configuration and Personas<br>
- Use remote (openai) and local (ollama) llm servers<br>
- Perform Context Management by builing and testing Prompts and only allowing tested prompts to be utilized<br>
- For each extracted requirement and using the llm team and the ontology should be interate on each requirment<br>
    - Extract any requirements contraints<br>
    - Review the requiement for efficacy and offer suggestions for improvment<br>
    - Per our base ontology or the specified ontology estimate the coneptual objects needed to for the requirements<br>
        - Estmate the Components and Interfaces<br>
        - Estimate the Processes<br>
        - Estimate the Functions and Conditions<br>
    - Liker terms shold be sqahed or clusted (airplane, aircraft, air-vehcile are all same entities)<br>
    - The coneptualization should be performed probabilistically, and clustered conetual systems identified (80% like this, 20% like that).<br>
    - The conceptualization should have convergence criteria<br>
    - The extracted conceptual models should be stored in the RDF and Graph dbs<br>
- The llms should only speak in the selected ontology data schema when asked to this should be a json formatted response<br>
- LLM Free talk is permissable unders some cercumstances to this schema output needs to be selectable<br>
- Permit additonal user generated requirements that can be reviewd by the llm team prior to acceptance<br>
- The UI should provide:<br>
    - Project/User Maintence<br>
    - File Uploading via selection or drag and drop<br>
    - Options to set the specific llm<br>
    - Query the RDF and Graph dbs<br>
    - Use a mcp like tools to automatically generate cyphers and sparql queires from user text<br>
    - Plot the graph db contexts for a specific coneptualization<br>
    - Review and interact with the requirments<br>
    - Generate requirements and coneptualization reports<br>
    - Allow SMEs to interace with the concept model and correct, change, edit via llm interactions (mcp like tool)<br>
    - The ability to upload a priori knowldege document for the llm knowledge, such as requirements writing techniques<br>
<br>
---<br>
Streach Goals:<br>
- Use a team of llm agents to extract the ontology<br>
- Extract an ontology from these requirements<br>
- The ontology should be extracted probabilistically and then we group or cluster general ontologies<br>
- The ontology extraction process should use convergence criteria to arrive at solutions<br>
- Allow a user to specify a teamwork cloud instance and export the concept as condept definitions for sysml models<br>
- Use BPMN model and camunda to build the processes as a part of the workflow<br>

