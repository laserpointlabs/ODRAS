ODRAS Demonstration Specification for NDIA 2025<br>
<br>
Purpose and context<br>
<br>
The U.S. Department of Defense issued a memorandum on August 20, 2025 directing the disestablishment of the Joint Capabilities Integration and Development System (JCIDS) and the creation of the Mission Engineering and Integration Activity (MEIA). The memo explains that the Joint Requirements Oversight Council (JROC) will focus on Key Operational Problems (KOPs), the Requirements and Resourcing Alignment Board (RRAB) will align these priorities with funding from a Joint Acceleration Reserve (JAR), and the Under Secretary of Defense for Research and Engineering must establish MEIA within 120 days[1]. MEIA’s role will be to engage with industry, conduct mission‑level engineering and iterative experimentation, and recommend validated solution elements to the RRAB[2].<br>
<br>
In parallel, the Mission Engineering Guide describes how mission engineering uses measures of effectiveness (MOEs) and measures of performance (MOPs) to assess mission success[3]. MOEs capture observable military effects that contribute to mission success, while MOPs record the performance of systems or actors carrying out the mission[4]. These measures help practitioners quantify and compare alternatives[5].<br>
<br>
The 28th Annual Systems & Mission Engineering Conference, organized by the National Defense Industrial Association (NDIA), will be held at the Grand Hyatt Tampa in Tampa, Florida from 27 to 30 October 2025[6]. This event brings together program managers, systems engineers, scientists and acquisition professionals to discuss improvements in defense acquisition and system performance[6]. It provides a public forum to showcase how new tools can support mission engineering and the DoD’s acquisition reforms.<br>
Demonstration goal<br>
<br>
LaserPoint Labs’ Ontology‑Driven Requirements Analysis System (ODRAS) is a research tool built on Camunda BPMN workflows, large‑language‑model (LLM) extraction, and semantic/graph stores (Qdrant, Fuseki and Neo4j). ODRAS automates the parsing of source documents, extracts candidate requirements using LLMs and heuristics, maps them to an ontology, and stores results for analysis. The goal for NDIA is not to solve the entire MEIA process, but to show how a single MEIA thread could be instantiated and executed using ODRAS.<br>
<br>
In this example we begin by selecting a realistic KOP scenario, such as assured resilient communications for distributed maritime operations. A representative capability document containing “shall/must/should” statements is uploaded into ODRAS; the existing extraction workflow identifies candidate requirements and populates a knowledge graph. We then define a small set of mission measures of effectiveness (MOEs) and measures of performance (MOPs) relevant to the scenario—for instance, message delivery success rate as an MOE and latency or bandwidth as MOPs. After choosing one or two solution alternatives, a simple experiment is designed to produce quantitative results aligned with the defined measures. Running this experiment through ODRAS (or a stub script) yields performance data and mission effects that can be stored in Neo4j and Fuseki. Finally, ODRAS compiles the findings into a concise executive summary that describes the extracted requirements, the selected measures, the experiment outcomes and a recommended solution. The resulting report serves as a mock “RRAB packet” and illustrates how MEIA outputs could feed the RRAB and JAR processes. The entire demonstration runs end‑to‑end in under five minutes on a local machine, emphasising transparency, repeatability and the idea that the MEIA process can be instantiated using software and produce auditable artifacts. Although simplified, this example illustrates how ODRAS can help programs or branches bootstrap a MEIA thread and evaluate solutions.<br>
<br>
Implementation notes<br>
The demonstration will integrate seamlessly with the existing ODRAS MVP architecture. ODRAS already includes a document ingestion pipeline built around a Camunda BPMN process that orchestrates PDF parsing, LLM extraction and storage of extracted requirements in Neo4j and Qdrant. To illustrate MEIA, a lightweight wrapper script—perhaps called meia_demo.py—will drive the steps of intake, engagement, mission analysis, experiment execution, validation and report generation. Each phase will create a clear artefact in the form of a markdown file, CSV or PDF in a ./demo_artifacts/<kop_id> folder.<br>
<br>
Mission metrics will follow the terminology from the Mission Engineering Guide. Measures of effectiveness describe the desired operational effects while measures of performance capture system performance[7]. For the sake of simplicity we will select only a handful of measures.<br>
<br>
The experiment does not need to be a full‑fidelity simulation. A deterministic script—based on a simple formula or random seed—can compute outcome metrics from input parameters to show how a single experiment cycle feeds the mission measures. The resulting data will still flow into the knowledge graph and support subsequent analysis.<br>
For report rendering, the final executive brief can be prepared in markdown and then converted to PDF using an existing conversion pipeline such as Pandoc or WeasyPrint. The brief should summarize the experiment results, describe the improvement in mission measures and offer a clear recommendation.<br>
<br>
Suggested demonstration script<br>
The demonstration script follows a straightforward sequence. First, we perform an intake step: a selected capability document is uploaded into ODRAS, the BPMN process extracts requirements and stores them, and a brief KOP‑INTAKE.md captures the KOP and mission context. Next comes mission analysis, where we create a Mission‑Data.yaml file containing the chosen MOEs and MOPs and an Alt‑Set.json describing the alternative solutions; we also map the extracted requirements to functions and measures in the ontology. After that we plan and run the experiment by writing an Experiment‑Plan.csv that lists the chosen alternative and mission measures and executing a simple script that produces Experiment‑Results.csv with outcome values for the MOE and MOP. Once the experiment data are available we summarise the results: we write a Validation‑Summary.md, convert it to PDF, prepare a RRAB‑Cover.md recommending the chosen solution, convert it to PDF and package these documents into a RRAB‑Packet.zip. Finally, we generate an Exec‑Brief.md that tells the story end‑to‑end—describing the KOP, the extracted requirements, the mission measures, the experiment outcomes and the recommended solution—and convert this brief to PDF for presentation.<br>
<br>
Prompt for implementation in ODRAS<br>
You are developing a first‑order demonstration of ODRAS to support the NDIA Systems & Mission Engineering Conference in Tampa (27–30 October 2025).  Your task is to build a runnable example that shows how MEIA might work for a single KOP.  The script should use the existing ODRAS document ingestion workflow to upload a sample capability document and extract its requirements into the Neo4j graph and Qdrant store.  After the document is ingested, create a mission analysis file defining measures of effectiveness and measures of performance relevant to the chosen mission scenario.  These definitions should follow the Mission Engineering Guide’s hierarchy, where MOEs capture operational effects and MOPs record system performance[5].  Next, define one or two alternative solutions and write a simple experiment plan that will generate mock outcome data aligned with the mission measures; store this data in the knowledge graph.  When the experiment is complete, produce a validation summary and assemble a mock RRAB packet recommending a solution element.  From these artefacts generate a concise executive brief that illustrates the improvement in mission measures and recommends a solution.<br>
<br>
The script should run in under five minutes on a local machine and produce auditable artefacts (markdown, CSV and PDF) in a `demo_artifacts` folder.  This demonstration is not intended to implement all of MEIA; it is a small, transparent example showing how ODRAS can instantiate a MEIA process thread and produce outputs suitable for RRAB review.<br>
________________________________________<br>
[1] [2] Secretary of Defense and Deputy Secretary of Defense memorandum<br>
https://www.newspacenexus.org/wp-content/uploads/2025/08/SecDef-Memo-20-Aug-2025.pdf<br>
[3] [4] [5] [7] Microsoft Word - (U)MEG_2.0_MASTER_v45 COPY<br>
https://ac.cto.mil/wp-content/uploads/2023/11/MEG_2_Oct2023.pdf<br>
[6] NDIA Systems & Mission Engineering Conference 2025<br>
https://www.ndia.org/events/2025/10/27/28th-annual-systems-and-mission-engineering-conference<br>

